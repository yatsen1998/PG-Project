{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f090f3ce",
   "metadata": {},
   "source": [
    "# Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62ebed47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/evanxu/opt/anaconda3/lib/python3.9/site-packages (3.2.1)\r\n",
      "Requirement already satisfied: py4j==0.10.9.3 in /Users/evanxu/opt/anaconda3/lib/python3.9/site-packages (from pyspark) (0.10.9.3)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5e384e",
   "metadata": {},
   "source": [
    "# Import NLTK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "296f51af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "import re\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef29a05",
   "metadata": {},
   "source": [
    "# Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d85341b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/evanxu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "22/04/12 15:53:07 WARN Utils: Your hostname, evanxus-MBP.local resolves to a loopback address: 127.0.0.1; using 172.24.0.4 instead (on interface feth4532)\n",
      "22/04/12 15:53:07 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/Users/evanxu/opt/anaconda3/lib/python3.9/site-packages/pyspark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/12 15:53:08 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "max_length = 4\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"COMP5349 Assignment1\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "def row_to_tuple_gl (row):\n",
    "  row_dict = row.asDict()\n",
    "  return (row_dict[\"Filename\"], row[\"Governing Law\"])\n",
    "\n",
    "def row_to_tuple_ac (row):\n",
    "  row_dict = row.asDict()\n",
    "  return (row_dict[\"Filename\"], row[\"Change of Control\"], row[\"Anti-assignment\"])\n",
    "\n",
    "# Use pySpark SQL to read CSV file\n",
    "governing_law_rdd_row = spark.read.csv(\"Governing_Law.csv\",header=True).rdd\n",
    "Assignment_CIC_rdd_row = spark.read.csv(\"Anti_assignment_CIC_g3.csv\",header=True).rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575b24d",
   "metadata": {},
   "source": [
    "# General Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aeb1696b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractPhrase(clause):\n",
    "    \"\"\" This function erases the stop words and punctuation, then converts the \n",
    "    rest of the clause into groups of words\n",
    "    \n",
    "    Args:\n",
    "        clause (str): A string of clause \n",
    "    Returns:\n",
    "        The return value is a list of listed words interrupted by stopwords \n",
    "    \"\"\"\n",
    "    clause = re.sub('[%s]' % re.escape(string.punctuation), '', clause)\n",
    "    word_list = word_tokenize(clause)\n",
    "    groups = groupby(word_list, lambda x: x not in stop_words)\n",
    "    phrases: List[Phrase] = [tuple(group[1]) for group in groups if group[0]]\n",
    "\n",
    "    return list(filter(lambda x: len(x) <= max_length, phrases))\n",
    "\n",
    "def flattenFirst(phrase_list):\n",
    "    \"\"\" This function preflat the 2D phrase_list into a 1D word list.\n",
    "    \n",
    "    Args:\n",
    "        phrase_list (str list): A 2D list of phrase\n",
    "    Returns:\n",
    "        The return value is a list of words \n",
    "    \"\"\"\n",
    "    word_list = []\n",
    "    for phrase in phrase_list:\n",
    "        for word in phrase:\n",
    "            word_list.append(word)\n",
    "    return word_list\n",
    "\n",
    "def getCoocur(phrase_list):\n",
    "    word_deg = {}\n",
    "    for phrase in phrase_list:\n",
    "        for word in phrase:\n",
    "            word_deg.setdefault(word, 0)\n",
    "            word_deg[word] += len(phrase) - 1\n",
    "    return word_deg\n",
    "\n",
    "def getElectedKeywords(doc):\n",
    "    \"\"\" This function calculate the first 4 elected words.\n",
    "    \n",
    "    Args:\n",
    "        phrase_list (str list): A string list of candidates\n",
    "    Returns:\n",
    "        The return value is a list of elected words\n",
    "    \"\"\"\n",
    "    freq = {}\n",
    "    deg = {}\n",
    "    score = {}\n",
    "    score_can = {}\n",
    "    for candidate in doc:\n",
    "        for word in candidate:\n",
    "            freq.setdefault(word, 0)\n",
    "            freq[word] += 1\n",
    "\n",
    "    for candidate in doc:\n",
    "        for word in candidate:\n",
    "            deg.setdefault(word, 0)\n",
    "            deg[word] += len(candidate) - 1\n",
    "    \n",
    "    for candidate in doc:\n",
    "        for word in candidate:\n",
    "            score.setdefault(word, 0)\n",
    "            score[word] = (deg[word] + freq[word]) / freq[word]\n",
    "            \n",
    "    for candidate in doc:\n",
    "        score_can.setdefault(candidate, 0)\n",
    "        for word in candidate:\n",
    "            score_can[candidate] += score[word]\n",
    "    sorted_score_can = sorted(score_can.items(), key=lambda d: d[1], reverse=True)\n",
    "    return sorted_score_can[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0e5509",
   "metadata": {},
   "source": [
    "# Method 1\n",
    "Each clause as a document and each category as a corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0951a834",
   "metadata": {},
   "source": [
    "## Governing Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "524e5c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('agreement shall', 205.29482071713147),\n",
       " ('governed', 47.07520891364903),\n",
       " ('agreement', 25.623529411764707),\n",
       " ('law principles', 24.324324324324323),\n",
       " ('laws', 24.31266149870801),\n",
       " ('new york', 20.571428571428573),\n",
       " ('new york without regard', 20.0),\n",
       " ('laws principles', 16.53125),\n",
       " ('construed', 16.318725099601593),\n",
       " ('law rules', 13.473684210526315),\n",
       " ('law provisions', 13.473684210526315),\n",
       " ('new york applicable', 12.0),\n",
       " ('delaware without regard', 12.0),\n",
       " ('california without regard', 12.0),\n",
       " ('laws provisions', 9.941176470588236),\n",
       " ('substantive laws', 9.333333333333334),\n",
       " ('parties hereto shall', 9.0),\n",
       " ('performed entirely within', 9.0),\n",
       " ('new york without reference', 9.0),\n",
       " ('performed wholly within', 8.0)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def row_to_tuple_gl_doc (row):\n",
    "    row_dict = row.asDict()\n",
    "    gl = row_dict[\"Governing Law\"]\n",
    "    # Remove page info\n",
    "    gl = re.sub('\\(Page.*?\\)', '', gl)\n",
    "    # Remove continuous space\n",
    "    gl = re.sub(' +', ' ', gl)\n",
    "    gl = gl.lower()\n",
    "    if gl == 'nan': \n",
    "        return (\"\")\n",
    "    return (gl)\n",
    "\n",
    "\n",
    "gl_candidate_list = governing_law_rdd_row.map(row_to_tuple_gl_doc)\\\n",
    "                                         .flatMap(lambda sentence: sentence.strip().split(\". \"))\\\n",
    "                                         .map(extractPhrase)\n",
    "\n",
    "# Calculate RDF list\n",
    "gl_rdf_list = gl_candidate_list.map(set)\\\n",
    "                               .flatMap(lambda xs: (x for x in xs))\\\n",
    "                               .map(lambda x: (x, 1))\\\n",
    "                               .reduceByKey(lambda x, y : x + y)\\\n",
    "                               .sortBy(lambda r: r[1], ascending=False)\n",
    "# gl_candidate_list.take(20)\n",
    "\n",
    "# Calculate score in each document\n",
    "gl_edf_list = gl_candidate_list.map(getElectedKeywords)\\\n",
    "                              .flatMap(lambda xs: (x[0] for x in xs))\\\n",
    "                              .map(lambda x: (x, 1))\\\n",
    "                              .reduceByKey(lambda x, y : x + y)\\\n",
    "                              .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "gl_ess_list = gl_rdf_list.join(gl_edf_list)\\\n",
    "                        .map(lambda x: (x[0], (x[1][1] * x[1][1]) / x[1][0]))\\\n",
    "                        .map(lambda x: (' '.join(x[0]), x[1]))\\\n",
    "                        .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "gl_ess_list.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134681ec",
   "metadata": {},
   "source": [
    "## Anti-assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6fb859fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('prior written consent', 192.60416666666666),\n",
       " ('neither party may assign', 43.0),\n",
       " ('either party without', 25.6),\n",
       " ('attempted assignment', 23.14814814814815),\n",
       " ('agreement without', 21.0125),\n",
       " ('agreement may', 20.897959183673468),\n",
       " ('either party may assign', 19.17391304347826),\n",
       " ('unreasonably withheld conditioned', 15.0),\n",
       " ('third party without', 13.473684210526315),\n",
       " ('neither party shall assign', 12.0),\n",
       " ('express written consent', 12.0),\n",
       " ('agreement shall', 11.0),\n",
       " ('neither party shall', 11.0),\n",
       " ('prior written approval', 10.0),\n",
       " ('obligations hereunder without', 9.0),\n",
       " ('express prior written consent', 9.0),\n",
       " ('violation', 9.0),\n",
       " ('consent shall', 8.595238095238095),\n",
       " ('party may assign', 8.470588235294118),\n",
       " ('third party', 8.16326530612245)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def row_to_tuple_aa_doc (row):\n",
    "    row_dict = row.asDict()\n",
    "    aa = row_dict[\"Anti-assignment\"]\n",
    "    if aa == None:\n",
    "        return (\"\")\n",
    "    # Remove page info\n",
    "    aa = re.sub('\\(Page.*?\\)', '', aa)\n",
    "    # Remove continuous space\n",
    "    aa = re.sub(' +', ' ', aa)\n",
    "    aa = aa.lower()\n",
    "    return (aa)\n",
    "\n",
    "aa_candidate_list = Assignment_CIC_rdd_row.map(row_to_tuple_aa_doc)\\\n",
    "                                         .flatMap(lambda sentence: sentence.strip().split(\". \"))\\\n",
    "                                         .map(extractPhrase)\n",
    "\n",
    "# Calculate RDF list\n",
    "aa_rdf_list = aa_candidate_list.map(set)\\\n",
    "                               .flatMap(lambda xs: (x for x in xs))\\\n",
    "                               .map(lambda x: (x, 1))\\\n",
    "                               .reduceByKey(lambda x, y : x + y)\\\n",
    "                               .sortBy(lambda r: r[1], ascending=False)\n",
    "# gl_candidate_list.take(20)\n",
    "\n",
    "# Calculate score in each document\n",
    "aa_edf_list = aa_candidate_list.map(getElectedKeywords)\\\n",
    "                              .flatMap(lambda xs: (x[0] for x in xs))\\\n",
    "                              .map(lambda x: (x, 1))\\\n",
    "                              .reduceByKey(lambda x, y : x + y)\\\n",
    "                              .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "aa_ess_list = aa_rdf_list.join(aa_edf_list)\\\n",
    "                        .map(lambda x: (x[0], (x[1][1] * x[1][1]) / x[1][0]))\\\n",
    "                        .map(lambda x: (' '.join(x[0]), x[1]))\\\n",
    "                        .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "aa_ess_list.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e45780f",
   "metadata": {},
   "source": [
    "## Change of Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "afc5627c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('prior written consent', 9.0),\n",
       " ('ownership transfer', 4.0),\n",
       " ('agreement may', 3.5),\n",
       " ('controlï¿½ shall mean', 3.0),\n",
       " ('control shall', 3.0),\n",
       " ('agreement immediately upon', 3.0),\n",
       " ('excitehome named competitor', 3.0),\n",
       " ('agreement upon written notice', 3.0),\n",
       " ('definitive agreement', 3.0),\n",
       " ('sole discretion terminate', 3.0),\n",
       " ('express written consent', 3.0),\n",
       " ('terminated upon', 3.0),\n",
       " ('licensor may terminate', 3.0),\n",
       " ('written notice', 2.7777777777777777),\n",
       " ('merger consolidation', 2.25),\n",
       " ('agreement shall terminate', 2.25),\n",
       " ('agreement shall', 2.25),\n",
       " ('party may assign', 2.0),\n",
       " ('c shall assign', 2.0),\n",
       " ('village media company', 2.0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def row_to_tuple_cc_doc (row):\n",
    "    row_dict = row.asDict()\n",
    "    cc = row_dict[\"Change of Control\"]\n",
    "    if cc == None:\n",
    "        return (\"\")\n",
    "    # Remove page info\n",
    "    cc = re.sub('\\(Page.*?\\)', '', cc)\n",
    "    # Remove continuous space\n",
    "    cc = re.sub(' +', ' ', cc)\n",
    "    cc = cc.lower()\n",
    "    return (cc)\n",
    "\n",
    "cc_candidate_list = Assignment_CIC_rdd_row.map(row_to_tuple_cc_doc)\\\n",
    "                                         .flatMap(lambda sentence: sentence.strip().split(\". \"))\\\n",
    "                                         .map(extractPhrase)\n",
    "\n",
    "# Calculate RDF list\n",
    "cc_rdf_list = cc_candidate_list.map(set)\\\n",
    "                               .flatMap(lambda xs: (x for x in xs))\\\n",
    "                               .map(lambda x: (x, 1))\\\n",
    "                               .reduceByKey(lambda x, y : x + y)\\\n",
    "                               .sortBy(lambda r: r[1], ascending=False)\n",
    "# gl_candidate_list.take(20)\n",
    "\n",
    "# Calculate score in each document\n",
    "cc_edf_list = cc_candidate_list.map(getElectedKeywords)\\\n",
    "                              .flatMap(lambda xs: (x[0] for x in xs))\\\n",
    "                              .map(lambda x: (x, 1))\\\n",
    "                              .reduceByKey(lambda x, y : x + y)\\\n",
    "                              .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "cc_ess_list = cc_rdf_list.join(cc_edf_list)\\\n",
    "                        .map(lambda x: (x[0], (x[1][1] * x[1][1]) / x[1][0]))\\\n",
    "                        .map(lambda x: (' '.join(x[0]), x[1]))\\\n",
    "                        .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "cc_ess_list.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e0ab94",
   "metadata": {},
   "source": [
    "# Method 2\n",
    "Each category as a document."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f32f96f",
   "metadata": {},
   "source": [
    "## Governing Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b1f76c2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('agreement shall', 962.9690721649507),\n",
       " ('laws', 605.8899676375408),\n",
       " ('state', 440.44285714285553),\n",
       " ('governed', 392.4730077120843),\n",
       " ('agreement', 308.3333333333333),\n",
       " ('accordance', 294.99661016949),\n",
       " ('construed', 281.1111111111112),\n",
       " ('new york without regard', 255.36229762389556),\n",
       " ('new york', 174.00158604282325),\n",
       " ('law principles', 139.19047619047612),\n",
       " ('conflict', 128.80000000000027),\n",
       " ('conflicts', 119.3684210526318),\n",
       " ('new york without reference', 115.39952041723953),\n",
       " ('california without regard', 107.16700940070508),\n",
       " ('delaware without regard', 106.56363761720901),\n",
       " ('laws principles', 103.96601941747576),\n",
       " ('new york applicable', 103.64903138099011),\n",
       " ('law', 96.42857142857147),\n",
       " ('principles', 86.16666666666664),\n",
       " ('internal laws', 79.7019057892844)]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def row_to_tuple_gl_doc (row):\n",
    "    row_dict = row.asDict()\n",
    "    gl = row_dict[\"Governing Law\"]\n",
    "    # Remove page info\n",
    "    gl = re.sub('\\(Page.*?\\)', '', gl)\n",
    "    # Remove continuous space\n",
    "    gl = re.sub(' +', ' ', gl)\n",
    "    gl = gl.lower()\n",
    "    return (gl)\n",
    "\n",
    "\n",
    "gl_list = governing_law_rdd_row.map(row_to_tuple_gl_doc)\\\n",
    "                               .flatMap(lambda sentence: sentence.strip().split(\". \"))\n",
    "\n",
    "gl_phrase_list = gl_list.map(extractPhrase)\n",
    "\n",
    "# Get freq(x)\n",
    "gl_word_freq = gl_phrase_list.map(flattenFirst)\\\n",
    "                             .flatMap(lambda xs: (x for x in xs))\\\n",
    "                             .map(lambda x: (x, 1))\\\n",
    "                             .reduceByKey(lambda x, y : x + y)\\\n",
    "                             .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "# Get Co-ocurrence of x\n",
    "gl_co_list = gl_phrase_list.map(getCoocur)\\\n",
    "                            .flatMap(lambda x: ((key, x[key]) for key in x.keys()))\\\n",
    "                            .reduceByKey(lambda x, y : x + y)\\\n",
    "                            .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "# Get Scores\n",
    "gl_scores = gl_word_freq.join(gl_co_list)\\\n",
    "                        .map(lambda x: (x[0], (x[1][0] + x[1][1])/x[1][0]))\n",
    "\n",
    "gl_scores_val = gl_scores.collectAsMap()\n",
    "\n",
    "def getGLPhraseScore(phrase_list):\n",
    "    phrase_score = {}\n",
    "    for phrase in phrase_list:\n",
    "        phrase_score.setdefault(tuple(phrase), 0)\n",
    "        for word in phrase:\n",
    "            phrase_score[tuple(phrase)] += gl_scores_val[word]\n",
    "    return phrase_score\n",
    "\n",
    "#Get Ranked list\n",
    "gl_ranked_list = gl_phrase_list.map(getGLPhraseScore)\\\n",
    "                               .flatMap(lambda x: ((key, x[key]) for key in x.keys()))\\\n",
    "                               .reduceByKey(lambda x, y : x + y)\\\n",
    "                               .map(lambda x: (' '.join(x[0]), x[1]))\\\n",
    "                               .sortBy(lambda r: r[1], ascending=False)\n",
    "# gl_ranked_list.take(5)\n",
    "\n",
    "gl_ranked_list.take(20)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4207e307",
   "metadata": {},
   "source": [
    "## Anti-assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "628da59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('prior written consent', 2162.390197970489),\n",
       " ('agreement', 682.0576923076922),\n",
       " ('party', 492.6967213114752),\n",
       " ('neither party may assign', 451.88285445870747),\n",
       " ('rights', 364.777472527472),\n",
       " ('assign', 325.0687679083097),\n",
       " ('agreement without', 324.41688963210714),\n",
       " ('either party without', 313.97688617504406),\n",
       " ('obligations', 287.2236842105267),\n",
       " ('third party', 272.6976989020905),\n",
       " ('unreasonably withheld', 259.32690507395637),\n",
       " ('either party may assign', 257.5352610126608),\n",
       " ('agreement may', 222.11172161172175),\n",
       " ('consent shall', 219.0690234667638),\n",
       " ('transfer', 209.88744588744558),\n",
       " ('consent', 193.8118811881189),\n",
       " ('obligations hereunder', 190.81015556847908),\n",
       " ('agreement shall', 190.20632373761194),\n",
       " ('assignment', 175.5),\n",
       " ('obligations hereunder without', 171.8660886492394)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def row_to_tuple_aa_doc (row):\n",
    "    row_dict = row.asDict()\n",
    "    aa = row_dict[\"Anti-assignment\"]\n",
    "    if aa == None:\n",
    "        return (\"\")\n",
    "    # Remove page info\n",
    "    aa = re.sub('\\(Page.*?\\)', '', aa)\n",
    "    # Remove continuous space\n",
    "    aa = re.sub(' +', ' ', aa)\n",
    "    aa = aa.lower()\n",
    "    return (aa)\n",
    "\n",
    "#Get\n",
    "aa_phrase_list = Assignment_CIC_rdd_row.map(row_to_tuple_aa_doc)\\\n",
    "                                       .flatMap(lambda sentence: sentence.strip().split(\". \"))\\\n",
    "                                       .map(extractPhrase)\n",
    "\n",
    "aa_word_freq = aa_phrase_list.map(flattenFirst)\\\n",
    "                             .flatMap(lambda xs: (x for x in xs))\\\n",
    "                             .map(lambda x: (x, 1))\\\n",
    "                             .reduceByKey(lambda x, y : x + y)\\\n",
    "                             .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "aa_co_list = aa_phrase_list.map(getCoocur)\\\n",
    "                            .flatMap(lambda x: ((key, x[key]) for key in x.keys()))\\\n",
    "                            .reduceByKey(lambda x, y : x + y)\\\n",
    "                            .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "aa_scores_val = aa_word_freq.join(aa_co_list)\\\n",
    "                        .map(lambda x: (x[0], (x[1][0] + x[1][1])/x[1][0]))\\\n",
    "                        .collectAsMap()\n",
    "\n",
    "\n",
    "def getAAPhraseScore(phrase_list):\n",
    "    phrase_score = {}\n",
    "    for phrase in phrase_list:\n",
    "        phrase_score.setdefault(tuple(phrase), 0)\n",
    "        for word in phrase:\n",
    "            phrase_score[tuple(phrase)] += aa_scores_val[word]\n",
    "    return phrase_score\n",
    "\n",
    "#Get Ranked list\n",
    "aa_ranked_list = aa_phrase_list.map(getAAPhraseScore)\\\n",
    "                               .flatMap(lambda x: ((key, x[key]) for key in x.keys()))\\\n",
    "                               .reduceByKey(lambda x, y : x + y)\\\n",
    "                               .map(lambda x: (' '.join(x[0]), x[1]))\\\n",
    "                               .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "aa_ranked_list.take(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef4970",
   "metadata": {},
   "source": [
    "## Change of Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "10986de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('agreement', 216.99555555555557),\n",
       " ('change', 191.0526315789476),\n",
       " ('control', 164.3999999999997),\n",
       " ('prior written consent', 150.3283793938382),\n",
       " ('party', 128.02162162162156),\n",
       " ('third party', 69.76607642124883),\n",
       " ('event', 66.90410958904108),\n",
       " ('transfer', 63.25714285714287),\n",
       " ('terminate', 62.6470588235294),\n",
       " ('agreement may', 60.004444444444445),\n",
       " ('written notice', 55.20229633679607),\n",
       " ('rights', 45.56862745098038),\n",
       " ('sale', 43.571428571428555),\n",
       " ('merger', 42.0943396226415),\n",
       " ('substantially', 40.526315789473685),\n",
       " ('effective date', 39.325),\n",
       " ('notice', 38.96774193548387),\n",
       " ('assignment', 38.07692307692306),\n",
       " ('merger consolidation succession', 36.920526014865644),\n",
       " ('assets', 35.57894736842106)]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def row_to_tuple_cc_doc (row):\n",
    "    row_dict = row.asDict()\n",
    "    cc = row_dict[\"Change of Control\"]\n",
    "    if cc == None:\n",
    "        return (\"\")\n",
    "    # Remove page info\n",
    "    cc = re.sub('\\(Page.*?\\)', '', cc)\n",
    "    # Remove continuous space\n",
    "    cc = re.sub(' +', ' ', cc)\n",
    "    cc = cc.lower()\n",
    "    return (cc)\n",
    "\n",
    "#Get\n",
    "cc_phrase_list = Assignment_CIC_rdd_row.map(row_to_tuple_cc_doc)\\\n",
    "                                       .flatMap(lambda sentence: sentence.strip().split(\". \"))\\\n",
    "                                       .map(extractPhrase)\n",
    "\n",
    "cc_word_freq = cc_phrase_list.map(flattenFirst)\\\n",
    "                             .flatMap(lambda xs: (x for x in xs))\\\n",
    "                             .map(lambda x: (x, 1))\\\n",
    "                             .reduceByKey(lambda x, y : x + y)\\\n",
    "                             .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "cc_co_list = cc_phrase_list.map(getCoocur)\\\n",
    "                            .flatMap(lambda x: ((key, x[key]) for key in x.keys()))\\\n",
    "                            .reduceByKey(lambda x, y : x + y)\\\n",
    "                            .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "cc_scores_val = cc_word_freq.join(cc_co_list)\\\n",
    "                        .map(lambda x: (x[0], (x[1][0] + x[1][1])/x[1][0]))\\\n",
    "                        .collectAsMap()\n",
    "\n",
    "\n",
    "def getCCPhraseScore(phrase_list):\n",
    "    phrase_score = {}\n",
    "    for phrase in phrase_list:\n",
    "        phrase_score.setdefault(tuple(phrase), 0)\n",
    "        for word in phrase:\n",
    "            phrase_score[tuple(phrase)] += cc_scores_val[word]\n",
    "    return phrase_score\n",
    "\n",
    "#Get Ranked list\n",
    "cc_ranked_list = cc_phrase_list.map(getCCPhraseScore)\\\n",
    "                               .flatMap(lambda x: ((key, x[key]) for key in x.keys()))\\\n",
    "                               .reduceByKey(lambda x, y : x + y)\\\n",
    "                               .map(lambda x: (' '.join(x[0]), x[1]))\\\n",
    "                               .sortBy(lambda r: r[1], ascending=False)\n",
    "\n",
    "cc_ranked_list.take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264d3885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
