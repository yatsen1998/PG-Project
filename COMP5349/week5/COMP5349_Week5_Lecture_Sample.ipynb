{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"colab":{"name":"COMP5349_Week5_Lecture_Sample.ipynb","provenance":[],"collapsed_sections":["1qZZ-xweYYRr","Fi_zlGN9YYRt"]}},"nbformat":4,"nbformat_minor":0,"cells":[{"cell_type":"markdown","source":["## Installing pyspark\n","\n","The following cell install the latest pyspark package"],"metadata":{"id":"wyvLA7vSrEuo"}},{"cell_type":"code","source":["!pip install pyspark"],"metadata":{"id":"5aPPITHmYevz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648712490423,"user_tz":-480,"elapsed":52863,"user":{"displayName":"Evan Xu","userId":"02479223528838433918"}},"outputId":"dc7b6b82-30ce-4ab9-eb50-5dc9d7d7beb6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyspark\n","  Downloading pyspark-3.2.1.tar.gz (281.4 MB)\n","\u001b[K     |████████████████████████████████| 281.4 MB 34 kB/s \n","\u001b[?25hCollecting py4j==0.10.9.3\n","  Downloading py4j-0.10.9.3-py2.py3-none-any.whl (198 kB)\n","\u001b[K     |████████████████████████████████| 198 kB 48.2 MB/s \n","\u001b[?25hBuilding wheels for collected packages: pyspark\n","  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyspark: filename=pyspark-3.2.1-py2.py3-none-any.whl size=281853642 sha256=08f06391d209e91ba51f7fb529e1384c5f7c108e16b8e95bafca410e02334ef8\n","  Stored in directory: /root/.cache/pip/wheels/9f/f5/07/7cd8017084dce4e93e84e92efd1e1d5334db05f2e83bcef74f\n","Successfully built pyspark\n","Installing collected packages: py4j, pyspark\n","Successfully installed py4j-0.10.9.3 pyspark-3.2.1\n"]}]},{"cell_type":"markdown","source":["## Mounting Google Drive\n","\n","The following cell mounts your google drive in the virtual machine runing the notebook. You will be asked to authenticate your account to access Google drive. Once authenticated, your google drive is mounted at `/content/drive`. Anything in your google drive can be accessed from `/content/drive/MyDrive`."],"metadata":{"id":"VAcHZpUqrJif"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"NFqA9KucYh-U","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648712576499,"user_tz":-480,"elapsed":16536,"user":{"displayName":"Evan Xu","userId":"02479223528838433918"}},"outputId":"5d1ddb98-280b-4a27-f07e-e590b1b72774"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["The following cell lists the content of your google drive. We assume you have created a folder called `comp5349` in your google drive and have uploaded the data file there."],"metadata":{"id":"I1SseUADrQdd"}},{"cell_type":"code","source":["!ls /content/drive/MyDrive"],"metadata":{"id":"cccM1-yZrRQ8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648712578442,"user_tz":-480,"elapsed":425,"user":{"displayName":"Evan Xu","userId":"02479223528838433918"}},"outputId":"9d46563f-dc3a-40f4-a508-3e179bc4c5cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["'Colab Notebooks'   COMP5216   comp5349   ELEC5517   INFO5990   INFO6007\n"]}]},{"cell_type":"markdown","metadata":{"id":"9duVTuxBYYRf"},"source":["### Initializing Spark\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3b9Qf784YYRj"},"outputs":[],"source":["from pyspark import SparkConf, SparkContext\n","\n","spark_conf = SparkConf()\\\n","        .setAppName(\"Week 5 Lecture Sample Code\")\n","sc=SparkContext.getOrCreate(spark_conf) \n"]},{"cell_type":"markdown","metadata":{"id":"HlwAHaERYYRl"},"source":["### Word Count Program ###\n","\n","This is the word count program used in week 5 lecture to illustrate basic spark program structure. It reads a text file from local disk and count the occurance of words in the text. For simplicity, words are considered as separaetd by white space only.\n","\n","**Each run of this cell will create an output directory called 1984_wordcount. To re-run the cell, you need to remove that directory from your google drive**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"deQl0RM8YYRm"},"outputs":[],"source":["input_file = 'file:///content/drive/MyDrive/comp5349/1984_processed.txt'\n","output_path = 'file:///content/drive/MyDrive/comp5349/1984_wordcount'\n","\n","text_file = sc.textFile(input_file)\n","\n","counts = text_file.flatMap(lambda line: line.strip().split(\" \")) \\\n","    .map(lambda word: (word, 1)) \\\n","    .reduceByKey(lambda a, b: a + b)\n","counts.saveAsTextFile(output_path)"]},{"cell_type":"markdown","metadata":{"id":"ZAb-4PCGYYRn"},"source":["## map style transformations\n","\n"," `map` vs. `mapValues`"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KMnWs7IjYYRn"},"outputs":[],"source":["d = [('a',1),('b',2),('c',3),('d',4),('e',5)]\n","distRDD = sc.parallelize(d)\n","\n","#convert to kms\n","kvmap= distRDD.map(lambda rec: (rec[0],rec[1] * 1.6)).collect()\n","kvmapvalues = distRDD.mapValues(lambda dist: dist * 1.6).collect()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"92l5HL-PYYRo","executionInfo":{"status":"ok","timestamp":1648117020009,"user_tz":-480,"elapsed":341,"user":{"displayName":"Evan Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj53AmmUk8uj7HMyp36vA6-rGE4mSZTf-P2KVF9=s64","userId":"02479223528838433918"}},"outputId":"d9308d8f-8831-4dc5-f661-c981e0117725"},"outputs":[{"output_type":"stream","name":"stdout","text":["[('a', 1.6), ('b', 3.2), ('c', 4.800000000000001), ('d', 6.4), ('e', 8.0)]\n","[('a', 1.6), ('b', 3.2), ('c', 4.800000000000001), ('d', 6.4), ('e', 8.0)]\n"]}],"source":["print(kvmap)\n","print(kvmapvalues)"]},{"cell_type":"markdown","metadata":{"id":"vhc5kWpYYYRo"},"source":["## map style transformation \n","\n","`filter`"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6rPB-06bYYRp","executionInfo":{"status":"ok","timestamp":1648175517547,"user_tz":-480,"elapsed":344,"user":{"displayName":"Evan Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj53AmmUk8uj7HMyp36vA6-rGE4mSZTf-P2KVF9=s64","userId":"02479223528838433918"}},"outputId":"fbc0812a-5364-4d05-ee17-686e9aa48480"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('c', 3), ('d', 4), ('e', 5)]"]},"metadata":{},"execution_count":15}],"source":["longDist = distRDD.filter(lambda rec: rec[1] > 2)\n","longDist.collect()"]},{"cell_type":"markdown","metadata":{"id":"a5x_mDfjYYRp"},"source":["### Movie Rating Computing ###\n","\n","This is a sample notebook showing basic spark RDD operations. The program has two input data sources: *ratings.csv* and *movies.csv*.\n","\n","The *movies.csv* file contains movie information. Each row represents one movie, and has the following format:\n","\n","`movieId,title,genres`\n","\n","The *ratings.csv* file contains rating information. Each row represents one rating of one movie by one user, and has the following format:\n","\n","`userId,movieId,rating,timestamp`\n"]},{"cell_type":"markdown","metadata":{"id":"Camlk1olYYRq"},"source":["#### The following cell defines a number of functions to be used in the computation ####"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tFui5TrxYYRq"},"outputs":[],"source":["import csv\n","\"\"\"\n","This module includes a few functions used in computing average rating per genre\n","\"\"\"\n","def pairMovieToGenre(record):\n","    \"\"\"This function converts entries of movies.csv into key,value pair of the following format\n","    (movieID, genre)\n","    since there may be multiple genre per movie, this function returns a list of tuples\n","    Args:\n","        record (str): A row of CSV file, with three columns separated by comma\n","    Returns:\n","        The return value is a list of tuples, each tuple contains (movieID, genre)\n","    \"\"\"\n","    for row in csv.reader([record]):\n","        if len(row) != 3:\n","            continue\n","        movieID, genreList = row[0],row[2]\n","        return [(movieID, genre) for genre in genreList.split(\"|\")]\n","\n","def extractRating(record):\n","    \"\"\" This function converts entries of ratings.csv into key,value pair of the following format\n","    (movieID, rating)\n","    Args:\n","        record (str): A row of CSV file, with four columns separated by comma\n","    Returns:\n","        The return value is a tuple (movieID, genre)\n","    \"\"\"\n","    try:\n","        userID, movieID, rating, timestamp = record.split(\",\")\n","        rating = float(rating)\n","        return (movieID, rating)\n","    except:\n","        return ()\n","\n","def mapToPair(line):\n","    \"\"\" This function converts tuples of (genre, rating) into key,value pair of the following format\n","    (genre,rating)\n","    \n","    Args:\n","        line (str): A tuple of  (genre, rating) \n","    Returns:\n","        The return value is a tuple  (genre, rating) \n","    \"\"\"\n","    genre, rating = line\n","    return (genre, rating)\n","\n","def avg(values):\n","    #convert the iterable into a list\n","    vlist = list(values) \n","    # the average is the sum of the list divided by the count of the the list\n","    return sum(vlist)/len(vlist)"]},{"cell_type":"markdown","metadata":{"id":"1qZZ-xweYYRr"},"source":["#### This cell defines the spark function  skeleton (e.g. the computation graph ####\n","\n","To facilitate inspection of each intermediate RDD, we write each transformation in a separate statement. This is not necessary in production code. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6q2MrnvBYYRs"},"outputs":[],"source":["input_path = 'file:///content/drive/MyDrive/comp5349/'\n","\n","#read the input as line and convert into RDD of String\n","ratingData = sc.textFile(input_path + \"ratings.csv\")\n","movieData = sc.textFile(input_path + \"movies.csv\")\n","\n","movieRatings = ratingData.map(extractRating)\n","# we use flatMap as there are multiple genre per movie\n","movieGenre = movieData.flatMap(pairMovieToGenre)\n","\n","# join  the two RDDs\n","joined = movieGenre.join(movieRatings)\n","# throw away the movieID which is useless for subsequent computation\n","joined_gk = joined.values()\n","# group ratings by genre\n","grouped = joined_gk.groupByKey()\n","genreRatingsAvg = grouped.mapValues(avg).collect()\n","\n","''' The short hand version\n","genreRatingsAvg = movieGenre \\\n","    .join(movieRatings) \\\n","    .values() \\\n","    .groupByKey() \\\n","    .mapValues(avg) \\\n","    .collect()\n","'''\n","genreRatingsAvg"]},{"cell_type":"markdown","metadata":{"id":"Fi_zlGN9YYRt"},"source":["#### Check RDD element ####"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NnOJRGS-YYRu","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648178097596,"user_tz":-480,"elapsed":363,"user":{"displayName":"Evan Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj53AmmUk8uj7HMyp36vA6-rGE4mSZTf-P2KVF9=s64","userId":"02479223528838433918"}},"outputId":"f97c5487-0985-4ec8-eac7-5173c872f7d3"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["['1,Toy Story (1995),Adventure|Animation|Children|Comedy|Fantasy',\n"," '2,Jumanji (1995),Adventure|Children|Fantasy']"]},"metadata":{},"execution_count":36}],"source":["#What does movieData look like\n","#Each row is a string\n","movieData.take(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iV_3E-2VYYRu","executionInfo":{"status":"ok","timestamp":1648178097597,"user_tz":-480,"elapsed":5,"user":{"displayName":"Evan Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj53AmmUk8uj7HMyp36vA6-rGE4mSZTf-P2KVF9=s64","userId":"02479223528838433918"}},"outputId":"7c67eff2-88fe-4e9b-f3f1-0214c8df35ec"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('16', 4.0), ('24', 1.5)]"]},"metadata":{},"execution_count":37}],"source":["# What does movieRatings RDD look like\n","# Each row is a tuple of String, float\n","movieRatings.take(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z-_FDylqYYRv","executionInfo":{"status":"ok","timestamp":1648178098343,"user_tz":-480,"elapsed":749,"user":{"displayName":"Evan Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj53AmmUk8uj7HMyp36vA6-rGE4mSZTf-P2KVF9=s64","userId":"02479223528838433918"}},"outputId":"61ce63e5-368e-4a6b-cada-3ad43c2c4bda"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["105339"]},"metadata":{},"execution_count":38}],"source":["#How many element are there in movieRatings\n","movieRatings.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v9D1yYS7YYRw","executionInfo":{"status":"ok","timestamp":1648178098344,"user_tz":-480,"elapsed":6,"user":{"displayName":"Evan Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj53AmmUk8uj7HMyp36vA6-rGE4mSZTf-P2KVF9=s64","userId":"02479223528838433918"}},"outputId":"431b2d98-f555-4837-ddc3-a8f9041ef7cb"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('1', 'Adventure'), ('1', 'Animation')]"]},"metadata":{},"execution_count":39}],"source":["#what does moveGenre RDD look like\n","#Each row is a tuple of string, string\n","movieGenre.take(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yyVfE_iJYYRw","outputId":"991727b0-1993-4df4-ed8d-6c967f434adf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648178098344,"user_tz":-480,"elapsed":4,"user":{"displayName":"Evan Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj53AmmUk8uj7HMyp36vA6-rGE4mSZTf-P2KVF9=s64","userId":"02479223528838433918"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["23114"]},"metadata":{},"execution_count":40}],"source":["#How many element are there in movieGenre\n","movieGenre.count()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0wj6voPuYYRx","outputId":"14df8c2f-8072-421d-d210-67e5fd397312","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648178098696,"user_tz":-480,"elapsed":355,"user":{"displayName":"Evan Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj53AmmUk8uj7HMyp36vA6-rGE4mSZTf-P2KVF9=s64","userId":"02479223528838433918"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('4', ('Comedy', 3.5)), ('4', ('Comedy', 3.0))]"]},"metadata":{},"execution_count":41}],"source":["#what does joined look like \n","# we are joinning (mid, genre) with (mid, rating)\n","# the result is (mid, (genre, rating))\n","joined.take(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tbSSi4yHYYRx","outputId":"5c6a3051-f6fd-4703-aac5-307d53b79103","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648178098698,"user_tz":-480,"elapsed":11,"user":{"displayName":"Evan Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj53AmmUk8uj7HMyp36vA6-rGE4mSZTf-P2KVF9=s64","userId":"02479223528838433918"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Comedy', 3.5), ('Comedy', 3.0)]"]},"metadata":{},"execution_count":42}],"source":["# What does joined_gk look like\n","# a tuple of (string, float) representing (genre, rating)\n","joined_gk.take(2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kYEzEZT2YYRy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648178098699,"user_tz":-480,"elapsed":10,"user":{"displayName":"Evan Xu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj53AmmUk8uj7HMyp36vA6-rGE4mSZTf-P2KVF9=s64","userId":"02479223528838433918"}},"outputId":"a653a9c0-850b-4340-a81d-2f968a510462"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('Drama', <pyspark.resultiterable.ResultIterable at 0x7f067a9fe990>),\n"," ('Romance', <pyspark.resultiterable.ResultIterable at 0x7f067a9fedd0>)]"]},"metadata":{},"execution_count":43}],"source":["# When we run groupByKey on joined_gk, all rating values \n","# for the same genre will be grouped into a single sequence as an iterable object\n","grouped.take(2)"]},{"cell_type":"markdown","source":["# Lab6 code\n"],"metadata":{"id":"Z4BdOGqs1pL3"}},{"cell_type":"code","source":["from pyspark import SparkConf, SparkContext\n","\n","spark_conf = SparkConf()\\\n","        .setAppName(\"Week 6 Lab Code\")\n","sc = SparkContext.getOrCreate(spark_conf)\n","\n","input_file = 'file:///content/drive/MyDrive/comp5349/1984_processed.txt'\n","output_path = 'file:///content/drive/MyDrive/comp5349/1984_wordcount'\n","\n","text_file = sc.textFile(input_file)\n","\n","bigrams = text_file.map(lambda line: line.strip().split(\" \"))\\\n","                 .flatMap(lambda xs: (tuple(x) for x in zip(xs, xs[1:])))\n","\n","result = bigrams.map(lambda x: (x, 1)).reduceByKey(lambda x, y: x + y).sortBy(lambda r: r[1],ascending=False)\n","\n","result.take(5)\n","\n","# bigrams = zip(words[:-1], words[1:])\n","\n","# result = bigrams.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b).sortBy(lambda r: r[1],ascending=False) \\"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xBN7Klz61nPf","executionInfo":{"status":"ok","timestamp":1648716672513,"user_tz":-480,"elapsed":1661,"user":{"displayName":"Evan Xu","userId":"02479223528838433918"}},"outputId":"5431f7e2-230a-45b2-b80e-5e8542babe0a"},"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(('big', 'brother'), 67),\n"," (('said', 'winston'), 43),\n"," (('old', 'man'), 38),\n"," (('thought', 'police'), 38),\n"," (('said', \"o'brien\"), 37)]"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["from pyspark import SparkConf, SparkContext\n","import csv\n","\n","spark_conf = SparkConf()\\\n","        .setAppName(\"Week 6 Lab Code\")\n","sc = SparkContext.getOrCreate(spark_conf)\n","\n","input_path = 'file:///content/drive/MyDrive/comp5349/'\n","\n","movieData = sc.textFile(input_path + \"movies.csv\")\n","\n","genre = 'Sci-Fi'\n","\n","def filterMovieInGenre(record):\n","    for row in csv.reader([record]):\n","        if len(row) != 3:\n","            continue\n","        year = row[1][-5:-1]\n","        genreList = row[2]\n","        genres = genreList.split('|')\n","        if genre in genres:\n","            return [year]\n","        else:\n","            return []\n","\n","genres = movieData.flatMap(filterMovieInGenre)\\\n","                  .map(lambda x: (x, 1))\\\n","                  .reduceByKey(lambda x, y : x + y)\\\n","                  .sortBy(lambda r: r[1],ascending=False)\n","\n","genres.take(5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kA1N8QU_KnVS","executionInfo":{"status":"ok","timestamp":1648719854203,"user_tz":-480,"elapsed":859,"user":{"displayName":"Evan Xu","userId":"02479223528838433918"}},"outputId":"460bc948-8f8e-4604-aca8-b08f2e88cec0"},"execution_count":110,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('2009', 49), ('2011', 33), ('2008', 32), ('2013', 30), ('2007', 27)]"]},"metadata":{},"execution_count":110}]}]}